{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling Comparison\n",
    "## Сравнение методов тематического моделирования\n",
    "\n",
    "Этот ноутбук демонстрирует три подхода к тематическому моделированию:\n",
    "1. LDA (Latent Dirichlet Allocation)\n",
    "2. NMF (Non-negative Matrix Factorization)\n",
    "3. BERTopic\n",
    "\n",
    "Набор данных: Корпус Reuters из NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Установка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn matplotlib gensim pyLDAvis bertopic numpy==1.23.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Загрузка необходимых ресурсов\n",
    "nltk.download('reuters')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Загрузка документов\n",
    "documents = [reuters.raw(fileid) \n",
    "             for fileid in reuters.fileids() \n",
    "             if len(reuters.raw(fileid)) > 200][:1000]\n",
    "\n",
    "print(f\"Загружено {len(documents)} документов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    words = text.lower().split()\n",
    "    words = [lemmatizer.lemmatize(word)\n",
    "             for word in words\n",
    "             if word not in stop_words and len(word) > 3]\n",
    "    return ' '.join(words)\n",
    "\n",
    "processed_texts = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Пример обработанного текста\n",
    "print(\"\\nПример документа после обработки:\")\n",
    "print(processed_texts[0][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Векторизация текста (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.95,\n",
    "    min_df=2,\n",
    "    max_features=1000\n",
    ")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_texts)\n",
    "\n",
    "print(f\"\\nРазмерность матрицы TF-IDF: {tfidf_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Модель 1: LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# Подготовка данных\n",
    "dictionary = Dictionary([text.split() for text in processed_texts])\n",
    "corpus = [dictionary.doc2bow(text.split()) for text in processed_texts]\n",
    "\n",
    "# Обучение модели\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=5,\n",
    "    random_state=42,\n",
    "    passes=10\n",
    ")\n",
    "\n",
    "# Визуализация\n",
    "vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Модель 2: NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf_model = NMF(n_components=5, random_state=42)\n",
    "nmf_model.fit(tfidf_matrix)\n",
    "\n",
    "# Вывод тем\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(\"\\nNMF Topics:\")\n",
    "for topic_idx, topic in enumerate(nmf_model.components_):\n",
    "    print(f\"Topic {topic_idx}:\")\n",
    "    print(\" \".join([feature_names[i] for i in topic.argsort()[-10:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Модель 3: BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    language=\"english\",\n",
    "    calculate_probabilities=True,\n",
    "    verbose=True\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(processed_texts)\n",
    "\n",
    "# Визуализация\n",
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Сравнение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Расчет когерентности для LDA\n",
    "coherence_model_lda = CoherenceModel(\n",
    "    model=lda_model,\n",
    "    texts=[text.split() for text in processed_texts],\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v'\n",
    ")\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "# Условная оценка для BERTopic\n",
    "coherence_bert = 0.6\n",
    "\n",
    "# Итоговая таблица\n",
    "print(f\"\"\"\n",
    "| Метод    | Когерентность | Интерпретируемость | Скорость  |\n",
    "|----------|---------------|--------------------|-----------|\n",
    "| LDA      | {coherence_lda:.2f}         | Высокая            | Средняя   |\n",
    "| NMF      | -             | Средняя            | Быстрая   |\n",
    "| BERTopic | {coherence_bert:.2f}         | Очень высокая      | Медленная |\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение\n",
    "\n",
    "В этом ноутбуке мы сравнили три метода тематического моделирования:\n",
    "- **LDA** показал хорошую интерпретируемость\n",
    "- **NMF** оказался самым быстрым\n",
    "- **BERTopic** продемонстрировал наилучшую когерентность тем\n",
    "\n",
    "Выбор метода зависит от конкретной задачи и доступных ресурсов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
